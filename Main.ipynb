{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMJcqPaM29eEa1kSzGdf2H/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Oscar-Hickman/Characterisation-of-photon-BEC-phase-diagram-using-machine-learning/blob/master/Main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BoHpIZ4qmbv",
        "outputId": "30a7919e-8ed5-4643-cb6e-50c26adbe803"
      },
      "source": [
        "!pip install -q healpy\r\n",
        "!pip install camb\r\n",
        "!pip install corner"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 15.8MB 319kB/s \n",
            "\u001b[?25hCollecting camb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/18/4221d569ed621da7e82e81aa8a5a76aae2dc0ee6786e7bbbdefd0df1f887/camb-1.3.0.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 9.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.6/dist-packages (from camb) (1.4.1)\n",
            "Requirement already satisfied: sympy>=1.0 in /usr/local/lib/python3.6/dist-packages (from camb) (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy>=1.0->camb) (1.19.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.6/dist-packages (from sympy>=1.0->camb) (1.1.0)\n",
            "Building wheels for collected packages: camb\n",
            "  Building wheel for camb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for camb: filename=camb-1.3.0-cp36-none-any.whl size=1045392 sha256=3c42540b3bb64be0ac24d4ca4a64ff028c57d222f5ff10189fb33ee16757f051\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/8a/29/bb0afc5b177f62f73266cd880fc1516d91c555b611bc80a5d5\n",
            "Successfully built camb\n",
            "Installing collected packages: camb\n",
            "Successfully installed camb-1.3.0\n",
            "Collecting corner\n",
            "  Downloading https://files.pythonhosted.org/packages/5a/ff/df5e34996aec8bc342c72714d1384e9af17259e6f60c2a63da2f53ba1631/corner-2.1.0-py2.py3-none-any.whl\n",
            "Collecting setuptools-scm\n",
            "  Downloading https://files.pythonhosted.org/packages/db/6e/2815f7c8561b088ccedc128681e64daac3d6b2e81a9918b007e244dad8b1/setuptools_scm-5.0.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib>=2.1 in /usr/local/lib/python3.6/dist-packages (from corner) (3.2.2)\n",
            "Requirement already satisfied: setuptools>=40.6.0 in /usr/local/lib/python3.6/dist-packages (from corner) (53.0.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.6/dist-packages (from corner) (0.36.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1->corner) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1->corner) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1->corner) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1->corner) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1->corner) (2.4.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib>=2.1->corner) (1.15.0)\n",
            "Installing collected packages: setuptools-scm, corner\n",
            "Successfully installed corner-2.1.0 setuptools-scm-5.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nv1_93_QqRPG"
      },
      "source": [
        "#Import Packages\r\n",
        "import tensorflow as tf\r\n",
        "import tensorflow_probability as tfp\r\n",
        "#from tensorflow_probability import experimental\r\n",
        "tfd = tfp.distributions\r\n",
        "import numpy as np\r\n",
        "import scipy as sp\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import healpy as hp\r\n",
        "#import pandas as pd\r\n",
        "import camb \r\n",
        "from camb import model, initialpower\r\n",
        "import glob\r\n",
        "import pylab as plty\r\n",
        "from PIL import Image\r\n",
        "from healpy.sphtfunc import Alm\r\n",
        "import time \r\n",
        "import corner\r\n",
        "#import seaborn as sns\r\n",
        "import scipy.stats as st\r\n",
        "from mpl_toolkits.mplot3d import Axes3D\r\n",
        "import os\r\n",
        "import sys\r\n",
        "\r\n",
        "\r\n",
        "#%%\r\n",
        "#Use CAMB to generate a power spectrum\r\n",
        "#Use CAMB to generate a power spectrum\r\n",
        "def call_CAMB_map(_parameters, _lmax): #lmax above 2551 makes no difference?\r\n",
        "    '''\r\n",
        "    parameters = [H0, ombh2, omch2, mnu, omk, tau]  = [Hubble Const, Baryon density, DM density, \r\n",
        "    Sum 3 neutrino masses/eV, Curvature parameter (Omega kappa), Reionisation optical depth]\r\n",
        "    '''\r\n",
        "    if _lmax <= 2551: #can only find power spectrum for lmax <= 2551 since that is the maximum value of the data.\r\n",
        "        pars = camb.CAMBparams()\r\n",
        "        pars.set_cosmology(H0 = _parameters[0], ombh2 = _parameters[1], omch2 = _parameters[2], mnu = _parameters[3],\r\n",
        "                   omk = _parameters[4], tau = _parameters[5])  #Inputs the given cosmological parameters.\r\n",
        "        pars.InitPower.set_params(As=2e-9, ns=0.965, r=0)\r\n",
        "        \r\n",
        "        pars.set_for_lmax(_lmax, lens_potential_accuracy=0) #input the given lmax value\r\n",
        "        \r\n",
        "        results = camb.get_results(pars)\r\n",
        "        powers =results.get_cmb_power_spectra(pars, CMB_unit='muK') #returns the power spectrum in units muK.\r\n",
        "        \r\n",
        "        totCL=powers['total'] #returns the total (averaged) power spectrum - including lensed, unlensed power spectra \r\n",
        "        _DL = totCL[:,0] \r\n",
        "        \r\n",
        "        #unlensedCL=powers['unlensed_scalar'] #returns the unlensed scalar power spectrum\r\n",
        "        #_DL = unlensedCL[:,0] # \r\n",
        "    \r\n",
        "        _l = np.arange(len(_DL)) #not sure this CL is actually CL but is actually DL\r\n",
        "        _CL = []\r\n",
        "        for i in range(_lmax): #also limits the length of power spectrum to the requested length\r\n",
        "            if i == 0:\r\n",
        "                _CL.append(_DL[i]) #since unsure what CL value is for this DL\r\n",
        "        \r\n",
        "            else:\r\n",
        "                _CL.append(_DL[i]/(_l[i]*(_l[i] + 1)))\r\n",
        "        \r\n",
        "        _CL = np.array(_CL)    \r\n",
        "    \r\n",
        "        return _CL \r\n",
        "    \r\n",
        "    else: #prints error if lmax is too large.\r\n",
        "        print('lmax value is larger than the available data.')\r\n",
        "        \r\n",
        "        \r\n",
        "#%%\r\n",
        "#Plots a given power spectrum \r\n",
        "def plotpwrspctrm(_cls):\r\n",
        "    _l = np.arange(len(_cls))\r\n",
        "    plt.plot(_l, _l * (_l + 1) * _cls)\r\n",
        "    plt.xlabel(\"$\\l$\")\r\n",
        "    plt.ylabel(\"$\\l(\\l+1)C_{\\l}$\")\r\n",
        "    plt.grid()\r\n",
        "    plt.title(\"Power Spectrum\")\r\n",
        "    \r\n",
        "#%%\r\n",
        "#Plots a map in the mollview projection \r\n",
        "def mollviewmap(_map):\r\n",
        "    hp.mollview(_map, title=\"Map displayed in the Molleview projection\", cmap = None)\r\n",
        "    hp.graticule()\r\n",
        "    \r\n",
        "#%%\r\n",
        "#Adds random noise to each pixel on a map given a variance \r\n",
        "def noisemapfunc(_map,_var):\r\n",
        "    _noisevec = np.random.normal(0,_var,len(_map)) #A vector of the noise applied to each pixel\r\n",
        "    _newmap = [x + y for x, y in zip(_map, _noisevec)]\r\n",
        "    _newmap, _noisevec = np.array(_newmap), np.array(_noisevec)\r\n",
        "    return [_newmap, _noisevec] #returns an array consisiting of [map with added noise, array of the added noise]\r\n",
        "\r\n",
        "#%%\r\n",
        "#cls --> something\r\n",
        "#cls --> something\r\n",
        "def cltoalm(_cls, _NSIDE, _lmax): #doesn't work (isnt currently being used)\r\n",
        "    _alms = []\r\n",
        "    _count = 0\r\n",
        "    for l in range(_lmax): \r\n",
        "        if _cls[l] > 0:\r\n",
        "            _alms.append(np.complex(np.random.normal(0,_cls[l]),0))        #set m=0, which is real\r\n",
        "        else:\r\n",
        "            _alms.append(np.complex(0,0))\r\n",
        "        \r\n",
        "        for m in range(l+1): #set positive m's\r\n",
        "            if _cls[l] > 0 and _cls[m] > 0:\r\n",
        "                _alms.append(np.complex(np.random.normal(0,0.5*_cls[l]),np.random.normal(0,0.5*_cls[m])))\r\n",
        "            if _cls[l] > 0 and _cls[m] <= 0:\r\n",
        "                _alms.append(np.complex(np.random.normal(0,0.5*_cls[l]),0))\r\n",
        "            if _cls[l] <= 0 and _cls[m] > 0:\r\n",
        "                _alms.append(np.complex(0,np.random.normal(0,0.5*_cls[m])))\r\n",
        "            else:\r\n",
        "                _alms.append(np.complex(0,0))\r\n",
        "    \r\n",
        "    return _alms   \r\n",
        "\r\n",
        "def hpcltoalm(_cls, _NSIDE, _lmax): #Healpy generate alms given cls\r\n",
        "    return hp.synalm(_cls, _lmax, new = True)\r\n",
        "\r\n",
        "def cltomap(_cls, _NSIDE, _lmax): #doesn't work (isnt currently being used)\r\n",
        "    _alm = cltoalm(_cls, _NSIDE, _lmax)\r\n",
        "    return almtomap(_alm, _NSIDE, _lmax)\r\n",
        "\r\n",
        "def hpcltomap(_cls, _NSIDE, _lmax):   #Healpy generate a map given a power spectrum\r\n",
        "    return hp.synfast(_cls, _NSIDE, _lmax, new=True) \r\n",
        "\r\n",
        "#%%\r\n",
        "#map --> something\r\n",
        "def maptocl(_map): #does this manually - doesn't work (isnt currently being used)\r\n",
        "    return\r\n",
        "\r\n",
        "def hpmaptocl(_map, _NSIDE, _lmax): #Generate a power spectrum given cls\r\n",
        "    return hp.anafast(_map, lmax = _lmax - 1)    #lmax = 3NSIDE by default\r\n",
        "\r\n",
        "def maptoalm(_map): #does this manually - doesn't work (isnt currently being used)\r\n",
        "    _omegp = (4*np.pi)/len(_map)\r\n",
        "    _lmax = int(np.sqrt(len(_map)*(3/4)))\r\n",
        "    _NSIDE = int(_lmax/3)\r\n",
        "    _alm = []\r\n",
        "    for l in range(_lmax):\r\n",
        "        for m in range(l+1):\r\n",
        "            _TpYlm = []\r\n",
        "            for i in range(len(_map)):\r\n",
        "                _TpYlm.append(_map[i]*np.conjugate(sphharm(m, l, i, _NSIDE)))\r\n",
        "                    \r\n",
        "            _alm.append(_omegp*sum(_TpYlm))\r\n",
        "    \r\n",
        "    return np.array(_alm)\r\n",
        "\r\n",
        "\r\n",
        "def hpmaptoalm(_map, _lmax): #Healpy generate alms from map. \r\n",
        "    return hp.map2alm(_map, _lmax-1)\r\n",
        "\r\n",
        "#alm --> something\r\n",
        "def almtocl(_alm, lmax): #alm --> cl using alms in my ordering (different to healpys).\r\n",
        "    _l = np.arange(lmax)\r\n",
        "    _scaling = 1 / ((2*_l + 1))\r\n",
        "    count = 0\r\n",
        "    _new = []\r\n",
        "    _cl = []\r\n",
        "    for l in range(lmax):\r\n",
        "        _new.append([])\r\n",
        "        for m in range(l):\r\n",
        "            if m == 0:\r\n",
        "                _new[l].append(np.absolute(_alm[count])**2)\r\n",
        "                count = count + 1\r\n",
        "                \r\n",
        "            if m > 0:\r\n",
        "                _new[l].append(2*np.absolute(_alm[count])**2)\r\n",
        "                count = count + 1\r\n",
        "              \r\n",
        "    for i in range(len(_new)):\r\n",
        "        _cl.append(_scaling[i] * sum(_new[i]))\r\n",
        "    \r\n",
        "    return _cl\r\n",
        "\r\n",
        "def hpalmtocl(_alms, _lmax): #Healpy estimates the power spectrum from the cls.\r\n",
        "    return hp.alm2cl(_alms, lmax = _lmax-1)\r\n",
        "\r\n",
        "def almtomap(_alm, _NSIDE, _lmax):# alm --> map using alms in my ordering (different to healpys).    #used in psi\r\n",
        "    _map = []\r\n",
        "    _Npix = 12*(_NSIDE)**2\r\n",
        "\r\n",
        "    for i in range(_Npix):\r\n",
        "        _sum = []\r\n",
        "        _count = 0\r\n",
        "        for l in np.arange(0,_lmax):\r\n",
        "            for m in np.arange(0,l+1):\r\n",
        "                if m == 0:\r\n",
        "                    _sum.append(_alm[_count]*sphharm(m,l,i, _NSIDE))\r\n",
        "                    _count = _count + 1\r\n",
        "                else:\r\n",
        "                    _sum.append(2*(np.real(_alm[_count])*np.real(sphharm(m,l,i, _NSIDE)) -\r\n",
        "                                   np.imag(_alm[_count])*np.imag(sphharm(m,l,i, _NSIDE))))\r\n",
        "                    _count = _count + 1\r\n",
        "        _map.append(sum(_sum))\r\n",
        "\r\n",
        "    return np.real(_map)\r\n",
        "        \r\n",
        "\r\n",
        "def almtomap_tf(_alm, _NSIDE, _lmax): #alm --> map for tensorflow using alms in my ordering (different to healpys).\r\n",
        "    _map = tf.constant([])\r\n",
        "    for i in range(12*(_NSIDE)**2):\r\n",
        "        _sum = tf.constant([])\r\n",
        "        _count = 0\r\n",
        "        for l in range(_lmax):\r\n",
        "            for m in range(l+1):\r\n",
        "                if m==0:\r\n",
        "                    _sum = tf.concat((_sum,[_alm[_count]*sphharm(m,l,i, _NSIDE)]), axis = 0)\r\n",
        "                    _count = _count + 1\r\n",
        "                else:\r\n",
        "                    _sum = tf.concat((_sum,[2*((np.real(_alm[_count]))*(np.real(sphharm(m,l,i, _NSIDE)))-\r\n",
        "                                               np.imag(_alm[_count])*np.imag(sphharm(m,l,i, _NSIDE)))]), axis = 0)\r\n",
        "                    _count = _count + 1\r\n",
        "        _map = tf.concat((_map,[sum(_sum)]), axis = 0)\r\n",
        "    return tf.convert_to_tensor(_map)\r\n",
        "\r\n",
        "\r\n",
        "def almtomap_tf2(_alm,_NSIDE, _lmax):\r\n",
        "    _map = tf.Variable([])\r\n",
        "    _ralm = tf.math.real(_alm) \r\n",
        "    _ialm = tf.math.imag(_alm) \r\n",
        "    _rsph = tf.math.real(_sph) \r\n",
        "    _isph = tf.math.imag(_sph) \r\n",
        "    _map = tf.Variable(np.array([]))\r\n",
        "    for i in range(12*(_NSIDE)**2):\r\n",
        "        _count = 0\r\n",
        "        _term1 = tf.Variable(0.0,dtype = np.float64)\r\n",
        "        for l in range(_lmax):\r\n",
        "            for m in range(l+1):\r\n",
        "                if m==0:\r\n",
        "                    tf.compat.v1.assign_add(_term1, _ralm[_count]*_rsph[i][_count])\r\n",
        "                    _count = _count + 1\r\n",
        "                else:\r\n",
        "                    tf.compat.v1.assign_add(_term1,2*(_ralm[_count]*_rsph[i][_count] - \r\n",
        "                                                                  _ialm[_count]*_isph[i][_count]),0.0)\r\n",
        "                    _count = _count + 1\r\n",
        "\r\n",
        "        _map = tf.concat((_map, [_term1]), axis = 0)\r\n",
        "    _map = tf.dtypes.cast(_map, np.float64)\r\n",
        "    return _map\r\n",
        "\r\n",
        "def almtomap_tf3(_alm,_NSIDE, _lmax):  #used in psitf\r\n",
        "    _ones = np.ones(len(_alm), dtype = np.complex128)\r\n",
        "    _count = 0\r\n",
        "    for l in range(_lmax):\r\n",
        "        for m in range(l+1):     \r\n",
        "            if m == 0:\r\n",
        "                _ones[_count] = np.complex(0.5,0)\r\n",
        "            _count = _count + 1\r\n",
        "    _ones = tf.convert_to_tensor(_ones)  \r\n",
        "    _alm = _ones*_alm\r\n",
        "    _ralm = tf.math.real(_alm) \r\n",
        "    _ialm = tf.math.imag(_alm) \r\n",
        "    _rsph = tf.math.real(_sph) \r\n",
        "    _isph = tf.math.imag(_sph) \r\n",
        "\r\n",
        "    _map1 = tf.linalg.matvec(_rsph,_ralm)\r\n",
        "    _map2 = tf.linalg.matvec(_isph,_ialm)\r\n",
        "    _map = 2*(_map1 - _map2)\r\n",
        "    return _map\r\n",
        "\r\n",
        "\r\n",
        "def hpalmtomap(_alms, _NSIDE, _lmax):\r\n",
        "    return hp.alm2map(_alms, _NSIDE ,_lmax-1)\r\n",
        "\r\n",
        "\r\n",
        "#%%\r\n",
        "#healpy smoothing for the map and the alms\r\n",
        "def hpmapsmooth(_map, _lmax): #smooths a given map with a gaussian beam smoother.\r\n",
        "    return _map #hp.smoothing(_map, lmax = _lmax)\r\n",
        "\r\n",
        "\r\n",
        "def hpalmsmooth(_alms): #smooths a given set of alms with a gaussian beam smoother.\r\n",
        "    return hp.smoothalm(_alms, fwhm = 0.0)\r\n",
        "\r\n",
        "#splits/rejoins the alms into real/imaginary parts so that they can be optimised with scipy.optimize.minimize()\r\n",
        "def singulartosplitalm(_alm):\r\n",
        "    _realalm, _imagalm = _alm.real, _alm.imag\r\n",
        "    return [_realalm, _imagalm]\r\n",
        "    \r\n",
        "\r\n",
        "def splittosingularalm(_realalm, _imagalm):\r\n",
        "    _alm = []\r\n",
        "    _ralmcount = 0\r\n",
        "    _ialmcount = 0\r\n",
        "    for l in range(lmax):\r\n",
        "        for m in range(l+1):\r\n",
        "            if m == 0 or m == 1:\r\n",
        "                _alm.append(complex(_realalm[_ralmcount], 0))\r\n",
        "                _ralmcount = _ralmcount + 1\r\n",
        "            else:\r\n",
        "                _alm.append(complex(_realalm[_ralmcount], _imagalm[_ialmcount]))\r\n",
        "                _ralmcount = _ralmcount + 1\r\n",
        "                _ialmcount = _ialmcount + 1\r\n",
        "          \r\n",
        "    return _alm\r\n",
        "\r\n",
        "\r\n",
        "def splittosingularalm_tf(_realalm, _imagalm): #takes the real and imaginary parts of the alms and creates a tensor\r\n",
        "    _zero = tf.zeros(1, dtype = np.float64)\r\n",
        "    _count = 0\r\n",
        "    for l in range(lmax): #pads zeros to to lmax = 0 values \r\n",
        "        for m in range(l + 1):\r\n",
        "            if m == 0 or m == 1: \r\n",
        "                if l == 0:\r\n",
        "                    _imagalm = tf.concat([_zero,_imagalm], axis = 0)\r\n",
        "                else:\r\n",
        "                    _front = _imagalm[:_count]\r\n",
        "                    _back = _imagalm[_count:]\r\n",
        "                    _term = tf.concat([_zero, _back] , axis = 0)\r\n",
        "                    _imagalm = tf.concat([_front, _term], axis = 0)\r\n",
        "            _count = _count + 1\r\n",
        "    return tf.complex(_realalm,_imagalm)\r\n",
        "\r\n",
        "\r\n",
        "#%%\r\n",
        "#Retrieves the spherical harmonics for a given, l, m and pixel number\r\n",
        "def sphharm(m, l, _pixno, _NSIDE):\r\n",
        "    _theta, _phi = hp.pix2ang(nside=_NSIDE, ipix=_pixno)\r\n",
        "    return sp.special.sph_harm(m, l, _phi, _theta)\r\n",
        "\r\n",
        "#%%\r\n",
        "#Changes the ordering of the alms from healpy to mine or vice versa\r\n",
        "def almmotho(_moalm, _lmax):\r\n",
        "    '''changing the alm ordering from my ordering to healpys'''\r\n",
        "    _hoalm = []\r\n",
        "    _count4 = []\r\n",
        "    _count5 = 0\r\n",
        "    for i in np.arange(2,_lmax+2):\r\n",
        "        _count4.append(_count5)\r\n",
        "        _count5=_count5+i\r\n",
        "    for i in range(_lmax):\r\n",
        "        _count1 = 0 \r\n",
        "        _count2 = np.arange(0,_lmax,1)\r\n",
        "        _count3 = np.arange(_lmax,0,-1)\r\n",
        "        for j in np.arange(i+1,_lmax+1):\r\n",
        "            _hoalm.append(_moalm[_count1+_count4[i]])\r\n",
        "            _count1 = _count1 + j\r\n",
        "    return np.array(_hoalm)\r\n",
        "\r\n",
        "\r\n",
        "def almhotmo(_hoalm, _lmax):\r\n",
        "    '''changing the alm ordering from healpys ordering to mine'''\r\n",
        "    _moalm = np.zeros(sum(np.arange(_lmax+1)), dtype = complex)\r\n",
        "    _count4 = []\r\n",
        "    _count5 = 0\r\n",
        "    for i in np.arange(2,_lmax+2):\r\n",
        "        _count4.append(_count5)\r\n",
        "        _count5 = _count5+i\r\n",
        "    _count1 = 0\r\n",
        "    for i in range(_lmax):\r\n",
        "        _count2 = 0    \r\n",
        "        for j in np.arange(i+1,_lmax+1):\r\n",
        "            _moalm[_count2 + _count4[i]] = _hoalm[_count1]\r\n",
        "            _count1 = _count1 + 1\r\n",
        "            _count2 = _count2 + j        \r\n",
        "    return np.array(_moalm)\r\n",
        "\r\n",
        "#%%\r\n",
        "def multtensor(_lmax,_lenalm):\r\n",
        "    _shape = np.zeros([_lmax,_lenalm]) #matrix for the calculation of the psi in psi_tf\r\n",
        "    _count = 0\r\n",
        "    for i in range(_lmax):\r\n",
        "        for j in np.arange(0,i+1):\r\n",
        "            if j == 0:\r\n",
        "                _shape[i][_count] = 1.0\r\n",
        "                _count = _count + 1\r\n",
        "            else:\r\n",
        "                _shape[i][_count] = 2.0\r\n",
        "                _count = _count + 1\r\n",
        "    return tf.convert_to_tensor(_shape, dtype = np.float64)\r\n",
        "\r\n",
        "\r\n",
        "#%%\r\n",
        "#negative log of the posterior, psi.\r\n",
        "def psi(_params, _map, _lmax, _NSIDE, _Ninv): #unnormalised log probability\r\n",
        "    _lncl, _realalm, _imagalm = [0,0], [], []\r\n",
        "    for i in range(len_cl-2):\r\n",
        "        _lncl.append(_params[i])\r\n",
        "    for i in range(len_ralm):\r\n",
        "        _realalm.append(_params[i + len_cl-2])\r\n",
        "    for i in range(len_ialm-(2*lmax-1)):\r\n",
        "        _imagalm.append(_params[i + len_cl-2 + len_ralm])\r\n",
        "\r\n",
        "    _d = _map\r\n",
        "    _a = splittosingularalm(_realalm, _imagalm)\r\n",
        "    _Ya = hpalmtomap(almmotho(_a,_lmax), _NSIDE, _lmax)\r\n",
        "    _BYa =  _Ya #mapsmooth(_Ya, _lmax)\r\n",
        "    \r\n",
        "    _elem, _term1, _term2, _psi1 ,_psi2, _psi3 = [], [], [], [], [], []\r\n",
        "    _sum = 0\r\n",
        "    \r\n",
        "    for i in range(len(_d)):\r\n",
        "        _elem.append(_d[i] - _BYa[i])\r\n",
        "        _psi1.append(0.5*(_elem[i]**2)*_Ninv[i]) #first term in the taylor paper \r\n",
        "    \r\n",
        "    _l = np.arange(lmax)\r\n",
        "    for i in range(len(_lncl)):\r\n",
        "        _psi2.append((_l[i] + 0.5)*(_lncl[i])) #second term in the taylor paper \r\n",
        "\r\n",
        "    _a = np.absolute(np.array(_a))**2\r\n",
        "    _as = np.matmul(shape.numpy(),_a)\r\n",
        "    _psi3 = 0.5*_as/np.exp(np.array(_lncl)) #third term in the taylor paper \r\n",
        "\r\n",
        "    _psi = sum(_psi1) + sum(_psi2) + sum(_psi3) \r\n",
        "    print('psi =',_psi)\r\n",
        "    return _psi\r\n",
        "\r\n",
        "\r\n",
        "#negative log of the posterior, psi.def psi(_params, _map, _lmax, _NSIDE, _Ninv): #unnormalised log probability    _lncl, _realalm, _imagalm = [0,0], [], []    for i in range(len_cl-2):        _lncl.append(_params[i])    for i in range(len_ralm):        _realalm.append(_params[i + len_cl-2])    for i in range(len_ialm-(2*lmax-1)):        _imagalm.append(_params[i + len_cl-2 + len_ralm])     _d = _map    _a = splittosingularalm(_realalm, _imagalm)    _Ya = hpalmtomap(almmotho(_a,_lmax), _NSIDE, _lmax)    _BYa =  _Ya #mapsmooth(_Ya, _lmax)        _elem, _term1, _term2, _psi1 ,_psi2, _psi3 = [], [], [], [], [], []    _sum = 0        for i in range(len(_d)):        _elem.append(_d[i] - _BYa[i])        _psi1.append(0.5*(_elem[i]**2)*_Ninv[i]) #first term in the taylor paper         _l = np.arange(lmax)    for i in range(len(_lncl)):        _psi2.append((_l[i] + 0.5)*(_lncl[i])) #second term in the taylor paper      _a = np.absolute(np.array(_a))**2    _as = np.matmul(shape.numpy(),_a)    _psi3 = 0.5*_as/np.exp(np.array(_lncl)) #third term in the taylor paper      _psi = sum(_psi1) + sum(_psi2) + sum(_psi3)     print('psi =',_psi)    return _psi\r\n",
        "def psi_tf(_params):\r\n",
        "    _map, _lmax, _NSIDE, _Ninv = noisemap_tf, lmax, NSIDE, Ninv\r\n",
        "    _lnclstart = tf.zeros(2, np.float64)\r\n",
        "    _lncl = tf.concat([_lnclstart,_params[:(len_cl - 2)]], axis = 0)\r\n",
        "    _realalm = _params[len_cl - 2:(len_ralm + len_cl - 2)]\r\n",
        "    _imagalm = _params[(len_ralm + len_cl - 2):]\r\n",
        "    \r\n",
        "    _d = _map\r\n",
        "    _a = splittosingularalm_tf(_realalm, _imagalm)\r\n",
        "    _Ya = almtomap_tf3(_a, _NSIDE, _lmax)\r\n",
        "    _BYa =  _Ya #mapsmooth(_Ya, _lmax)\r\n",
        "    \r\n",
        "    _elem = _d - _BYa\r\n",
        "    _psi1 = 0.5*(_elem**2)*_Ninv #first term in the taylor paper \r\n",
        "    \r\n",
        "    _l = tf.range(_lmax, dtype = np.float64)\r\n",
        "    _psi2 = (_l+0.5)*_lncl #second term in the taylor paper \r\n",
        "    \r\n",
        "    _a = tf.math.abs(_a)**2\r\n",
        "    _as = tf.linalg.matvec(shape,_a)\r\n",
        "    _psi3 = 0.5*_as/tf.math.exp(_lncl) #third term in the taylor paper \r\n",
        "        \r\n",
        "    _psi = tf.reduce_sum(_psi1) + tf.reduce_sum(_psi2) + tf.reduce_sum(_psi3) \r\n",
        "    #print(_psi)\r\n",
        "    __psi_record.append(_psi)\r\n",
        "    #print('psi1',tf.reduce_sum(_psi1),'psi2',tf.reduce_sum(_psi2),'psi3',tf.reduce_sum(_psi3))\r\n",
        "    return _psi\r\n",
        "\r\n",
        "#%%\r\n",
        "#Run the normal hmc sampler\r\n",
        "def run_chain_hmc(initial_state, num_results = 25, num_burnin_steps=0): \r\n",
        "    '''Returns the desired walks through parameter space for a fixed step size.'''\r\n",
        "    return tfp.mcmc.sample_chain(num_results=num_results, num_burnin_steps=num_burnin_steps, \r\n",
        "                               current_state=initial_state, kernel=hmc_kernel, trace_fn=lambda current_state,\r\n",
        "                               kernel_results: kernel_results)\r\n",
        "\r\n",
        "#Run the nut sampler chain\r\n",
        "def run_chain_nut(initial_state, num_results=1000, num_burnin_steps=0): \r\n",
        "    '''Returns the desired walks through parameter space for a fixed step size.'''\r\n",
        "    return tfp.mcmc.sample_chain(num_results=num_results, num_burnin_steps=num_burnin_steps, \r\n",
        "                               current_state=initial_state, kernel=nut_kernel, trace_fn=lambda current_state,\r\n",
        "                               kernel_results: kernel_results)\r\n",
        "\r\n",
        "#%%\r\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBEPPr2RqnRU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}